import pandas as pd

configfile: "config.yml"

# import our dataset specific rules
module aqueduct:
    snakefile: "pipelines/aqueduct/rules.smk"
    config: config
use rule * from aqueduct as aqueduct_*
ruleorder: aqueduct_POST_metadata_to_backend > POST_metadata_to_backend

module jrc_pop:
    snakefile: "pipelines/jrc_pop/rules.smk"
    config: config
use rule * from jrc_pop as jrc_pop_*
ruleorder: jrc_pop_clip_and_reproject_raster > clip_raster

# prefix any shell blocks with these statements
# create variables from env file and export
# print commands to stdout prior to execution
shell.prefix(f"set -a && source ../envs/{config['environment']}/.etl.env && set +a; set -x ;")

# wildcards must not contain slashes
wildcard_constraints:
    LAYER="[^/]+",
    DATASET="[^/]+",

# datasets the `all` target rule will expand to
ALL_DATASETS = [
    "aqueduct",
    "jrc_pop"
]


rule set_zero_to_no_data:
    input:
        "raster/raw/{DATASET}/{KEY}.tif"
    output:
        temp("raster/no_data/{DATASET}/{KEY}.tif")
    resources:
        disk_mb=3000,
        mem_mb=10000,
    priority:
        70,
    shell:
        """
        NODATA=$(gdalinfo "{input}" -json | jq .bands[0].noDataValue)

        # handle case of NODATA == nan - the JSON output of gdalinfo will change
        # nan to "NaN" so we need to reverse that for gdal_calc.py
        if [ "$NODATA" == '"NaN"' ]
        then
          NODATA=nan
        fi

        if [ "$NODATA" == 'null' ]
        then
          NODATA=nan
        fi

        # replace zeros with NoData value
        gdal_calc.py \
          --quiet \
          -A "{input}" \
          --co="COMPRESS=LZW" \
          --outfile="{output}" \
          --overwrite \
          --calc="numpy.where(A<=0,$NODATA,A)" \
          --NoDataValue=$NODATA \
          --hideNoData
        """


def projwin_bounds(bbox: dict[str, float]) -> str:
    """
    Given dict of `minx`, `miny`, `maxx` and `maxy`, return coordinates as
    concatentated string in correct order for gdal_translate -projwin argument.
    """
    extents = (bbox["minx"], bbox["maxy"], bbox["maxx"], bbox["miny"])
    return " ".join(map(lambda extent: f"{extent:.3f}", extents))


rule clip_raster:
    """
    Clip raster extent to window defined by `raster_bounds` in config.
    """
    input:
        "raster/no_data/{DATASET}/{KEY}.tif"
    output:
        temp("raster/clip/{DATASET}/{KEY}.tif")
    params:
        bounds = projwin_bounds(config["raster_bounds"])
    resources:
        disk_mb=3000,
        mem_mb=10000,
    priority:
        80,
    shell:
        """
        gdal_translate \
            -co "COMPRESS=LZW" \
            -projwin {params.bounds} \
            -of GTiff \
            {input} \
            {output}
        """


rule cloud_optimise_raster:
    """
    Use terracotta to cloud optimise rasters.
    """
    input:
        "raster/clip/{DATASET}/{KEY}.tif"
    output:
        "raster/cog/{DATASET}/{KEY}.tif",
    resources:
        disk_mb=100,
        mem_mb=2000,
    threads: 2
    priority:
        90,
    shell:
        """
        terracotta optimize-rasters \
            -o $(dirname {output}) \
            --overwrite \
            --reproject \
            --nproc {threads} \
            --resampling-method nearest \
            {input}
        """


rule POST_metadata_to_backend:
    """
    Requires the `backend` and postgreSQL `db` services to be running.
    """
    input:
        ingest_flag = "pipelines/{DATASET}/ingested_to_mysql.flag",
        metadata = "pipelines/{DATASET}/metadata.json",
    output:
        flag = "pipelines/{DATASET}/posted_to_backend.flag"
    shell:
        """
        # N.B. 4XX responses result in a zero-valued httpie exit status
        http POST http://$BE_HOST:$BE_PORT/tiles/sources x-token:$BE_API_TOKEN < {input.metadata}

        touch {output.flag}
        """


rule all:
    """
    Target rule to fetch, process and ingest all registered datasets.
    """
    input:
        lambda x: expand("pipelines/{dataset}/posted_to_backend.flag", dataset=ALL_DATASETS)