import subprocess

import fiona
import geopandas
import pandas

from geoalchemy2.shape import to_shape
from pyproj import CRS, Transformer
from shapely.geometry import shape, mapping
from shapely.ops import transform
from sqlalchemy import delete
from sqlalchemy.orm import Session
from tqdm import tqdm

from backend.db.database import SessionLocal
from backend.db.models import Feature

# Example config
# - override by running:
#    snakemake --cores=1 --configfile=config_local.yml all
configfile: "config.yml"
hazard_layers = pandas.read_csv(config['hazard_layers'])
network_layers = pandas.read_csv(config['network_layers'])
network_tilelayers = pandas.read_csv(config['network_tilelayers'])

wildcard_constraints:
    layer="[^/.]+"

# Run all file-base jobs, after load_to_database
rule all:
    input:
        # expand("../tileserver/vector/data/{layer}.mbtiles", layer=network_layers.output_layer_name)
        # expand("../tileserver/raster/data/{slug}.tif", slug=hazard_layers.slug)


# Prerequisite, not fully traced by file dependency
#   snakemake --cores=all load_to_database
rule load_to_database:
    input:
        expand("vector/{layer}.txt", layer=network_layers.ref)


def get_network_layer(layer_name):
    try:
        return network_layers[network_layers.ref == layer_name].iloc[0]
    except IndexError as e:
        print(f"Could not find {layer_name} in network layers.")
        raise e


def get_network_layer_path(layer):
    return f"{config['analysis_data_dir']}/processed_data/networks_uids/{layer.path}"


def clean_props(props, rename):
    clean = {}
    for k, v in props.items():
        if k in rename:
            clean[rename[k]] = v
        elif k in rename.values():
            clean[f"_{k}"] = v
        else:
            clean[k] = v
    return clean


def get_tilelayer(layer_name):
    try:
        return network_tilelayers[network_tilelayers.layer == layer_name].iloc[0]
    except IndexError as e:
        print(f"Could not find {layer_name} in tilelayers.")
        raise e


def get_tilelayer_by_asset_type(props):
    try:
        return network_tilelayers[network_tilelayers.asset_type == props['asset_type']].iloc[0]
    except IndexError as e:
        print(f"Could not find {props['asset_type']} in tilelayers.")
        raise e


def get_tilelayers_by_network_source(network_source):
    try:
        return network_tilelayers[network_tilelayers.ref == network_source].layer
    except IndexError as e:
        print(f"Could not find {network_source} in tilelayers.")
        raise e


def yield_features(layer):
    """Read from file layer to modelled Features
    """
    with fiona.open(get_network_layer_path(layer), layer=layer.gpkg_layer) as src:
        from_crs = src.crs
        to_crs = CRS.from_epsg(4326)
        t = Transformer.from_crs(from_crs, to_crs, always_xy=True).transform
        def to_2d(x, y, z=None):
            return (x, y)

        rename = {
            layer.asset_id_column: 'asset_id',
            layer.asset_type_column: 'asset_type',
            layer.asset_min_cost_column: 'cost_min',
            layer.asset_max_cost_column: 'cost_max',
            layer.asset_mean_cost_column: 'cost_mean',
            layer.asset_cost_unit_column: 'cost_unit',
            layer.asset_reopen_cost_column: 'cost_reopen',
            layer.asset_reopen_cost_unit_column: 'cost_reopen_unit',
        }

        for feature in src:
            geom = transform(t, shape(feature['geometry']))
            if geom.has_z:
                geom = transform(to_2d, geom)
            props = clean_props(feature['properties'], rename)
            # FIXME in the data
            if layer.ref == 'transport_rail_edges':
                props['asset_type'] = 'track'
            tilelayer_details = get_tilelayer_by_asset_type(props)
            props['sector'] = tilelayer_details.sector
            props['subsector'] = tilelayer_details.sector

            yield Feature(
                id=props['uid'],
                string_id=props['asset_id'],
                layer=tilelayer_details.layer,
                properties=props,
                geom=geom.wkt
            )


rule networks_to_db:
    """Read from source directory to database
    """
    output:
        "vector/{layer}.txt"
    run:
        layer = get_network_layer(wildcards.layer)
        tilelayers = list(get_tilelayers_by_network_source(wildcards.layer))
        db: Session
        with SessionLocal() as db:
            db.execute(delete(Feature).where(Feature.layer.in_(tilelayers)))
            db.commit()

            for i, feature in tqdm(enumerate(yield_features(layer)), total=layer['count']):
                db.add(feature)
                if i % 1000 == 0:
                    db.commit()
            db.commit()

        with open(str(output), 'w') as fh:
            fh.write(f"Loaded to database.\n\n")
            fh.write(f"From:\n{get_network_layer_path(layer)}|{layer.gpkg_layer}\n\n")
            fh.write(f"Details:\n{str(layer)}\n")


rule damages_to_db:
    input:
        damage=f"{config['analysis_data_dir']}/results/direct_damages_summary_uids/{{layer}}_damages.parquet",
        exposure=f"{config['analysis_data_dir']}/results/direct_damages_summary_uids/{{layer}}_exposures.parquet",
        loss=f"{config['analysis_data_dir']}/results/direct_damages_summary_uids/{{layer}}_losses.parquet",
        expected=f"{config['analysis_data_dir']}/results/direct_damages_summary_uids/{{layer}}_EAD_EAEL.parquet",
    output:
        "vector/{layer}.damages.txt"
    run:
        # airport_polygon_areas
        print(input.damage)
        print(input.expected)


def make_feature_properties(feature: Feature):
    properties = {
        "asset_id": feature.properties['asset_id'],
        "asset_type": feature.properties['asset_type']
    }
    for damage in feature.damages:
        key = f"{damage.hazard}__rcp_{damage.rcp}__epoch_{damage.epoch}__conf_None"
        properties[key] = damage.EAD_undefended_mean
    return properties


def feature_as_geojson(feature: Feature):
    properties = make_feature_properties(feature)
    return {
        "type": "Feature",
        "id": feature.id,
        "geometry": mapping(to_shape(feature.geom)),
        "properties": properties,
    }


def yield_features_for_layer(layer: str):
    db: Session
    with SessionLocal() as db:
        for feature in db.query(Feature).filter(Feature.layer == layer):
            yield feature


rule db_to_geojsonseq:
    """Load from database to GeoJSONSeq
    """
    output:
        "vector/{layer}.geojsonl"
    run:
        with open(str(output), 'w') as fh:
            for feature in yield_features_for_layer(wildcards.layer):
                geojson = feature_as_geojson(feature)
                fh.write(json.dumps(geojson, indent=None))
                fh.write("\n")


rule geojsonseq_to_vector_tiles:
    input:
        "vector/{layer}.geojsonl"
    output:
        "../tileserver/vector/data/{layer}.mbtiles"
    run:
        layer = get_tilelayer(wildcards.layer)
        if layer.spatial_type == 'line':
          options=["--drop-densest-as-needed", "--minimum-zoom=3", "--maximum-zoom=15"]
        elif layer.spatial_type == 'polygon':
          options=["--drop-densest-as-needed", "--minimum-zoom=3", "--maximum-zoom=15"]
        else:
          options=["-zg"]

        subprocess.run([
            "tippecanoe",
            "--use-attribute-for-id=uid",
            "--read-parallel",
            f"--output={output}",
            f"--layer={wildcards.layer}"
        ] + options + [
            "--force",
            f"{input}"
        ])


rule raster_zero_nodata:
    output:
        temp("nodata-{slug}.tif"),
    shell:
        """
        NODATA=$(gdalinfo "{input}" -json | jq .bands[0].noDataValue)

        # handle case of NODATA == nan - the JSON output of gdalinfo will change
        # nan to "NaN" so we need to reverse that for gdal_calc.py
        if [ "$NODATA" == '"NaN"' ]# then
          NODATA=nan
        fi

        # replace zeros with NoData value
        gdal_calc.py \
          -A "{input}" \
          --outfile="{output}" \
          --overwrite \
          --calc="numpy.where(A==0,$NODATA,A)" \
          --hideNoData \
          --NoDataValue=$NODATA
        """


rule raster_to_cog:
    input:
        rules.raster_zero_nodata.output,
    output:
        "../tileserver/raster/data/{slug}.tif",
    shell:
        """
        # translate to Cloud-Optimised GeoTIFF
        # TODO tune COG conversion parameters or try terracotta optimize-rasters
        gdal_translate "{input}" "{output}" -of COG
        """
