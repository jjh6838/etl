import os
import subprocess
import shutil
from typing import List
import shutil

import geopandas
import pandas


def disk_free_mb(wildcards, attempt):
    _, _, free = shutil.disk_usage("/") 
    return int(free / 1000000)

# Load Config
configfile: "/opt/etl/pipelines/traveltime_to_healthcare/config.yml"


# Read further configuration data from CSV
exposure_layers = pandas.read_csv(config["exposure_layers"])


wildcard_constraints:
    layer="[^/]+",

# Run all file-base jobs, after load_to_database
rule all:
    input:
        expand("/opt/tileserver/raster/data/traveltime_to_healthcare/{layer}.tif", layer=exposure_layers.key),

rule raster_temp_file:
    output:
        "/opt/etl/raster/link/{layer}.tif",
    resources:
        disk_mb=100
    priority:
        60,
    run:
        layer = get_layer(wildcards.layer, exposure_layers)
        print (layer.path, output)
        shutil.copyfile(
            layer.path,
            str(output)
        )

def get_layer(layer_name, exposure_layers):
    try:
        print ("getting  layer: ", layer_name)
        return exposure_layers[exposure_layers.key == layer_name].iloc[0]
    except IndexError as e:
        print(f"Could not find {layer_name} in exposure layers.")
        raise e
    finally:
        print ("got exposure layer")

rule raster_zero_nodata:
    input:
        rules.raster_temp_file.output,
    output:
        "/opt/etl/raster/nodata/{layer}.tif",
    resources:
        disk_mb=3000
    priority:
        70,
    shell:
        """
        NODATA=$(gdalinfo "{input}" -json | jq .bands[0].noDataValue)

        # replace NoData with Zeros
        gdal_calc.py \
          --quiet \
          -A "{input}" \
          --outfile="{output}" \
          --overwrite \
          --calc="numpy.where(A==$NODATA,0,A)" \
          --NoDataValue=0 \
          --hideNoData && \
        rm {input}
        """

rule raster_clip_ns:
    input:
        rules.raster_zero_nodata.output,
    output:
        "/opt/etl/raster/clip/{layer}.tif",
    resources:
        disk_mb=3000
    priority:
        80,
    shell:
        """
        gdal_translate -projwin -175 84 175 -84 -of GTiff -co COMPRESS=LZW {input} {output} && \
        rm {input}
        """

rule raster_to_cog:
    input:
        rules.raster_clip_ns.output,
    output:
        "/opt/etl/raster/cog/{layer}.tif",
    resources:
        disk_mb=100
    priority:
        90,
    shell:
        """
        # translate to Cloud-Optimised GeoTIFF
        #
        # could use gdalwarp directly - options chosen to match (reasonably
        # closely) the output of `terracotta optimize-rasters`:
        #
        # gdalwarp "{input}" "{output}" \
        #     -t_srs "EPSG:3857" \
        #     -r near \
        #     -of COG \
        #     -co COMPRESS=DEFLATE \
        #     -co BLOCKSIZE=256
        #
        terracotta optimize-rasters \
            -o /opt/etl/raster/cog \
            --overwrite \
            --reproject \
            --nproc -1 \
            --resampling-method nearest \
            {input} && \
        rm {input}
        """

rule raster_cleanup:
    input:
        rules.raster_to_cog.output,
    output:
        "/opt/tileserver/raster/data/jrc_pop/{layer}.tif",
    resources:
        disk_mb=100
    priority:
        100,
    shell:
        """
        mv {input} {output}
        """
        